%! Author = kaliw
%! Date = 12/9/2019

% Introduction

Our project was a quite simple implementation of a Neural Network architecture to learn how to master the all-time favorite game of Tic Tac Toe.
The inspiration for this project came from AlphaZero, the elegant framework used to defeat world-class Go players such as Lee Sedol.
AlphaZero generalized on the Alpha Go framework and thus can be applied to all games of a certain class, namely if a turn based game with perfect knowledge at each turn.
AlphaZero also relies solely on self-play to build the training data for the network;
needing only the rules of the game to begin playing.
At the onset of this project we set out to completely replicate this framework, but instead we took some key lessons from AlphaZero and created our own framework which we aptly named AlphaEpsilon.

In AlphaEpsilon, we retain the \textit{tabular rasa} state of the network, providing only the rules for the game and no other human input.
We also retain the idea of self-play, where we create a set of play state data to then feed into the neural network to train.
